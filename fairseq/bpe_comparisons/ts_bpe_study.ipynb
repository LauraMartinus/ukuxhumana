{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ts_bpe_study.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "rbZJFNEOlsgi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Installing Pytorch"
      ]
    },
    {
      "metadata": {
        "id": "FQTz09F_l5Ry",
        "colab_type": "code",
        "outputId": "d27b2627-3f17-44b2-9e78-7c028bbeb091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x57a9a000 @  0x7f719d2e92a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D2uXn6IgmI_h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Building Fairseq"
      ]
    },
    {
      "metadata": {
        "id": "u8DXFDikmIqK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pytorch/fairseq.git\n",
        "import os\n",
        "os.chdir(\"fairseq/\")\n",
        "!pip install -r requirements.txt\n",
        "%run -i 'setup.py' build develop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dvMtXVjuBaK4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model for Nso"
      ]
    },
    {
      "metadata": {
        "id": "BHvh6LWAVj2D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data"
      ]
    },
    {
      "metadata": {
        "id": "Z6hMhJCxVmYc",
        "colab_type": "code",
        "outputId": "e5c96ea1-2d01-4fdd-9d5d-21fd42b84d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/LauraMartinus/ukuxhumana.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ukuxhumana'...\n",
            "remote: Enumerating objects: 56, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 1322 (delta 26), reused 21 (delta 8), pack-reused 1266\u001b[K\n",
            "Receiving objects: 100% (1322/1322), 386.31 MiB | 21.64 MiB/s, done.\n",
            "Resolving deltas: 100% (633/633), done.\n",
            "Checking out files: 100% (302/302), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uv7RW7fR9Yeg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Subword"
      ]
    },
    {
      "metadata": {
        "id": "hALHCsup9X52",
        "colab_type": "code",
        "outputId": "0e2a77a3-09db-4b0a-ff85-7811b47e5c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rsennrich/subword-nmt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'subword-nmt'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 485 (delta 0), reused 1 (delta 0), pack-reused 481\u001b[K\n",
            "Receiving objects: 100% (485/485), 205.64 KiB | 768.00 KiB/s, done.\n",
            "Resolving deltas: 100% (287/287), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wHpzQrY59dIb",
        "colab_type": "code",
        "outputId": "8b17e8a3-cde2-4758-b93a-155874b88c01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "#os.chdir('../')\n",
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "build\t\t      fairseq\t\tmultiprocessing_train.py  scripts\n",
            "CONTRIBUTING.md       fairseq.egg-info\tPATENTS\t\t\t  setup.py\n",
            "distributed_train.py  fairseq.gif\tpreprocess.py\t\t  subword-nmt\n",
            "docs\t\t      generate.py\tREADME.md\t\t  tests\n",
            "eval_lm.py\t      interactive.py\trequirements.txt\t  train.py\n",
            "examples\t      LICENSE\t\tscore.py\t\t  ukuxhumana\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BOqfutkh9U6P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat ukuxhumana/clean/en_nso/ennso_parallel.train.en ukuxhumana/clean/en_nso/ennso_parallel.train.nso > combine.txt\n",
        "\n",
        "# Learn a vocabulary using 40,000 merge operations\n",
        "!fairseq/subword-nmt/learn_bpe.py -s 4000 <combine.txt> ennso.codes\n",
        "\n",
        "# Apply the vocabulary to the training file\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < ukuxhumana/clean/en_nso/ennso_parallel.train.en > train.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < ukuxhumana/clean/en_nso/ennso_parallel.train.nso > train.nso\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < ukuxhumana/clean/en_nso/ennso_parallel.dev.en > valid.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < ukuxhumana/clean/en_nso/ennso_parallel.dev.nso > valid.nso\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < ukuxhumana/clean/en_nso/ennso_parallel.test.en > test.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < ukuxhumana/clean/en_nso/ennso_parallel.test.nso > test.nso"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zgN47Lks-MYt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('fairseq/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VvH9D2RQBdiZ",
        "colab_type": "code",
        "outputId": "068d2a3e-c951-415e-e6ac-c95ed9c302e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "TEXT=\"..\"\n",
        "%run 'preprocess.py' --source-lang en --target-lang nso --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test --destdir data-bin/ennso"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(alignfile=None, destdir='data-bin/ennso', joined_dictionary=False, nwordssrc=-1, nwordstgt=-1, only_source=False, output_format='binary', padding_factor=8, source_lang='en', srcdict=None, target_lang='nso', testpref='../test', tgtdict=None, thresholdsrc=0, thresholdtgt=0, trainpref='../train', validpref='../valid', workers=1)\n",
            "| [en] Dictionary: 2991 types\n",
            "| [en] ../train.en: 21543 sents, 672811 tokens, 0.0% replaced by <unk>\n",
            "| [en] Dictionary: 2991 types\n",
            "| [en] ../valid.en: 6234 sents, 192753 tokens, 0.0223% replaced by <unk>\n",
            "| [en] Dictionary: 2991 types\n",
            "| [en] ../test.en: 3000 sents, 69973 tokens, 0.0171% replaced by <unk>\n",
            "| [nso] Dictionary: 3415 types\n",
            "| [nso] ../train.nso: 21543 sents, 738066 tokens, 0.0% replaced by <unk>\n",
            "| [nso] Dictionary: 3415 types\n",
            "| [nso] ../valid.nso: 6234 sents, 208039 tokens, 0.0269% replaced by <unk>\n",
            "| [nso] Dictionary: 3415 types\n",
            "| [nso] ../test.nso: 3000 sents, 78649 tokens, 0.0839% replaced by <unk>\n",
            "| Wrote preprocessed data to data-bin/ennso\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lsk8qqhmBjSw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train Model"
      ]
    },
    {
      "metadata": {
        "id": "z7zy0QquBmsg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p chckpoint/fconv\n",
        "!python train.py data-bin/ennso \\\n",
        "    --lr 0.25 --clip-norm 0.1 --dropout 0.2 --max-tokens 4000 \\\n",
        "    --arch fconv --save-dir ckpoint/fconv\n",
        "\n",
        "# for sentencepiece remove ▁\n",
        "output = %run 'generate.py' data-bin/ennso --path ckpoint/fconv/checkpoint_best.pt --beam 5 --batch-size 128 --remove-bpe --source-lang en --target-lang nso"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z74u-7RbBs6o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Testing\n",
        "Generate translations from the test data. Calculate the Bleu score."
      ]
    },
    {
      "metadata": {
        "id": "sAGRGvz2Bv5m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for sentencepiece remove ▁\n",
        "output = %run 'generate.py' data-bin/ennso --path ckpoint/fconv/checkpoint_best.pt --beam 5 --batch-size 128 --remove-bpe --source-lang en --target-lang nso"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K8HW8jAKyXvG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**8k**"
      ]
    },
    {
      "metadata": {
        "id": "eLiTF-i1_aeX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('../')\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qosFjU2fyY_l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat ukuxhumana/clean/en_nso/ennso_parallel.train.en ukuxhumana/clean/en_nso/ennso_parallel.train.nso > combine.txt\n",
        "!fairseq/subword-nmt/learn_bpe.py -s 8000 <combine.txt> ennso.codes\n",
        "\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < ukuxhumana/clean/en_nso/ennso_parallel.train.en > train.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < ukuxhumana/clean/en_nso/ennso_parallel.train.nso > train.nso\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < ukuxhumana/clean/en_nso/ennso_parallel.dev.en > valid.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < ukuxhumana/clean/en_nso/ennso_parallel.dev.nso > valid.nso\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < ukuxhumana/clean/en_nso/ennso_parallel.test.en > test.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < ukuxhumana/clean/en_nso/ennso_parallel.test.nso > test.nso\n",
        "\n",
        "os.chdir('fairseq/')\n",
        "TEXT=\"..\"\n",
        "%run 'preprocess.py' --source-lang en --target-lang nso --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test --destdir data-bin/ennso\n",
        "\n",
        "!mkdir -p checkpoint/fconv\n",
        "!python train.py data-bin/ennso \\\n",
        "    --lr 0.25 --clip-norm 0.1 --dropout 0.2 --max-tokens 4000 \\\n",
        "    --arch fconv --save-dir checkpoint/fconv\n",
        "\n",
        "# for sentencepiece remove ▁\n",
        "output = %run 'generate.py' data-bin/ennso --path checkpoint/fconv/checkpoint_best.pt --beam 5 --batch-size 128 --remove-bpe --source-lang en --target-lang nso"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iHwS-r_UyZh1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**12k**"
      ]
    },
    {
      "metadata": {
        "id": "3p_Vap6Wya29",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('../')\n",
        "!cat ukuxhumana/clean/en_nso/ennso_parallel.train.en ukuxhumana/clean/en_nso/ennso_parallel.train.nso > combine.txt\n",
        "!fairseq/subword-nmt/learn_bpe.py -s 12000 <combine.txt> ennso.codes\n",
        "\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < ukuxhumana/clean/en_nso/ennso_parallel.train.en > train.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < ukuxhumana/clean/en_nso/ennso_parallel.train.nso > train.nso\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < ukuxhumana/clean/en_nso/ennso_parallel.dev.en > valid.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < ukuxhumana/clean/en_nso/ennso_parallel.dev.nso > valid.nso\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < ukuxhumana/clean/en_nso/ennso_parallel.test.en > test.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < ukuxhumana/clean/en_nso/ennso_parallel.test.nso > test.nso\n",
        "\n",
        "os.chdir('fairseq/')\n",
        "TEXT=\"..\"\n",
        "%run 'preprocess.py' --source-lang en --target-lang nso --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test --destdir data-bin/ennso\n",
        "\n",
        "!mkdir -p checkpoint/fconv\n",
        "!python train.py data-bin/ennso \\\n",
        "    --lr 0.25 --clip-norm 0.1 --dropout 0.2 --max-tokens 4000 \\\n",
        "    --arch fconv --save-dir chekpoint/fconv\n",
        "\n",
        "# for sentencepiece remove ▁\n",
        "output = %run 'generate.py' data-bin/ennso --path chekpoint/fconv/checkpoint_best.pt --beam 5 --batch-size 128 --remove-bpe --source-lang en --target-lang nso"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rYnfAuBpybUN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**16k**"
      ]
    },
    {
      "metadata": {
        "id": "8NDuR8KMidiq",
        "colab_type": "code",
        "outputId": "f325dcaa-5271-416c-afc9-5651d7e48384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "os.chdir('content/')\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "combine.txt  ennso.codes  fairseq  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nqrE4wDSydDu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#os.chdir('../')\n",
        "!cat fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.en fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.nso > combine.txt\n",
        "!fairseq/subword-nmt/learn_bpe.py -s 16000 <combine.txt> ennso.codes\n",
        "\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.en > train.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.nso > train.nso\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.dev.en > valid.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.dev.nso > valid.nso\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.test.en > test.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.test.nso > test.nso\n",
        "\n",
        "os.chdir('fairseq/')\n",
        "TEXT=\"..\"\n",
        "%run 'preprocess.py' --source-lang en --target-lang nso --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test --destdir data-bin/ennso\n",
        "\n",
        "!mkdir -p checkpoint/fconv\n",
        "!python train.py data-bin/ennso \\\n",
        "    --lr 0.25 --clip-norm 0.1 --dropout 0.2 --max-tokens 4000 \\\n",
        "    --arch fconv --save-dir checkpoint/fconv\n",
        "\n",
        "# for sentencepiece remove ▁\n",
        "output = %run 'generate.py' data-bin/ennso --path checkpoint/fconv/checkpoint_best.pt --beam 5 --batch-size 128 --remove-bpe --source-lang en --target-lang nso"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2HTIUWVFydem",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**20k**"
      ]
    },
    {
      "metadata": {
        "id": "FGdqisAf933c",
        "colab_type": "code",
        "outputId": "ed73230f-14f0-42d5-f2dd-05221d77cc93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "build\t\t      examples\t\tmultiprocessing_train.py  setup.py\n",
            "checkpoint\t      fairseq\t\tPATENTS\t\t\t  subword-nmt\n",
            "CONTRIBUTING.md       fairseq.egg-info\tpreprocess.py\t\t  tests\n",
            "data-bin\t      fairseq.gif\tREADME.md\t\t  train.py\n",
            "distributed_train.py  generate.py\trequirements.txt\t  ukuxhumana\n",
            "docs\t\t      interactive.py\tscore.py\n",
            "eval_lm.py\t      LICENSE\t\tscripts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UmN6Roccye1e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('../')\n",
        "!cat fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.en fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.nso > combine.txt\n",
        "!fairseq/subword-nmt/learn_bpe.py -s 20000 <combine.txt> ennso.codes\n",
        "\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.en > train.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.nso > train.nso\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.dev.en > valid.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.dev.nso > valid.nso\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.test.en > test.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.test.nso > test.nso\n",
        "\n",
        "os.chdir('fairseq/')\n",
        "TEXT=\"..\"\n",
        "%run 'preprocess.py' --source-lang en --target-lang nso --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test --destdir data-bin/ennso\n",
        "\n",
        "!mkdir -p checkpoint/fconv\n",
        "!python train.py data-bin/ennso \\\n",
        "    --lr 0.25 --clip-norm 0.1 --dropout 0.2 --max-tokens 4000 \\\n",
        "    --arch fconv --save-dir chckpoint/fconv\n",
        "\n",
        "# for sentencepiece remove ▁\n",
        "output = %run 'generate.py' data-bin/ennso --path chckpoint/fconv/checkpoint_best.pt --beam 5 --batch-size 128 --remove-bpe --source-lang en --target-lang nso"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cfq9EL8CyfWw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**24k**"
      ]
    },
    {
      "metadata": {
        "id": "Rv3xryb5f3h2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aVHz8s4Lygnm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('../')\n",
        "!cat fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.en fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.nso > combine.txt\n",
        "!fairseq/subword-nmt/learn_bpe.py -s 24000 <combine.txt> ennso.codes\n",
        "\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.en > train.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.nso > train.nso\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.dev.en > valid.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.dev.nso > valid.nso\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.test.en > test.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.test.nso > test.nso\n",
        "\n",
        "os.chdir('fairseq/')\n",
        "TEXT=\"..\"\n",
        "%run 'preprocess.py' --source-lang en --target-lang nso --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test --destdir data-bin/ennso\n",
        "\n",
        "!mkdir -p checkpoint/fconv\n",
        "!python train.py data-bin/ennso \\\n",
        "    --lr 0.25 --clip-norm 0.1 --dropout 0.2 --max-tokens 4000 \\\n",
        "    --arch fconv --save-dir chekpoint/fconv\n",
        "\n",
        "# for sentencepiece remove ▁\n",
        "output = %run 'generate.py' data-bin/ennso --path chekpoint/fconv/checkpoint_best.pt --beam 5 --batch-size 128 --remove-bpe --source-lang en --target-lang nso"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mt9VPBPqyhIt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**28k**"
      ]
    },
    {
      "metadata": {
        "id": "DCHKH53s_tfp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('../')\n",
        "!cat fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.en fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.nso > combine.txt\n",
        "!fairseq/subword-nmt/learn_bpe.py -s 28000 <combine.txt> ennso.codes\n",
        "\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.en > train.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.nso > train.nso\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.dev.en > valid.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.dev.nso > valid.nso\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.test.en > test.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.test.nso > test.nso\n",
        "\n",
        "os.chdir('fairseq/')\n",
        "TEXT=\"..\"\n",
        "%run 'preprocess.py' --source-lang en --target-lang nso --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test --destdir data-bin/ennso\n",
        "\n",
        "!mkdir -p checkpoint/fconv\n",
        "!python train.py data-bin/ennso \\\n",
        "    --lr 0.25 --clip-norm 0.1 --dropout 0.2 --max-tokens 4000 \\\n",
        "    --arch fconv --save-dir checkpoint/fconv\n",
        "\n",
        "# for sentencepiece remove ▁\n",
        "output = %run 'generate.py' data-bin/ennso --path checkpoint/fconv/checkpoint_best.pt --beam 5 --batch-size 128 --remove-bpe --source-lang en --target-lang nso"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "321XJhen_xtq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**32k**"
      ]
    },
    {
      "metadata": {
        "id": "lv4ICMNIVu70",
        "colab_type": "code",
        "outputId": "6f351728-53d2-4ffc-b269-5b84018aaaf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "build\t\t      examples\t\tmultiprocessing_train.py  setup.py\n",
            "checkpoint\t      fairseq\t\tPATENTS\t\t\t  subword-nmt\n",
            "CONTRIBUTING.md       fairseq.egg-info\tpreprocess.py\t\t  tests\n",
            "data-bin\t      fairseq.gif\tREADME.md\t\t  train.py\n",
            "distributed_train.py  generate.py\trequirements.txt\t  ukuxhumana\n",
            "docs\t\t      interactive.py\tscore.py\n",
            "eval_lm.py\t      LICENSE\t\tscripts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ChBPsrYQ_z_q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('../')\n",
        "!cat fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.en fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.nso > combine.txt\n",
        "!fairseq/subword-nmt/learn_bpe.py -s 32000 <combine.txt> ennso.codes\n",
        "\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.en > train.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.nso > train.nso\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.dev.en > valid.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.dev.nso > valid.nso\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.test.en > test.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.test.nso > test.nso\n",
        "\n",
        "os.chdir('fairseq/')\n",
        "TEXT=\"..\"\n",
        "%run 'preprocess.py' --source-lang en --target-lang nso --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test --destdir data-bin/ennso\n",
        "\n",
        "!mkdir -p chckpoint/fconv\n",
        "!python train.py data-bin/ennso \\\n",
        "    --lr 0.25 --clip-norm 0.1 --dropout 0.2 --max-tokens 4000 \\\n",
        "    --arch fconv --save-dir chckpoint/fconv\n",
        "\n",
        "# for sentencepiece remove ▁\n",
        "output = %run 'generate.py' data-bin/ennso --path chckpoint/fconv/checkpoint_best.pt --beam 5 --batch-size 128 --remove-bpe --source-lang en --target-lang nso"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t5LX6mOzRhz2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**36k**"
      ]
    },
    {
      "metadata": {
        "id": "KH1I8T06VNkb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#os.chdir('fairseq/')\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qs3FqDYvRk0M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('../')\n",
        "!cat fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.en fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.nso > combine.txt\n",
        "!fairseq/subword-nmt/learn_bpe.py -s 36000 <combine.txt> ennso.codes\n",
        "\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.en > train.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.nso > train.nso\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.dev.en > valid.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.dev.nso > valid.nso\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.test.en > test.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.test.nso > test.nso\n",
        "\n",
        "os.chdir('fairseq/')\n",
        "TEXT=\"..\"\n",
        "%run 'preprocess.py' --source-lang en --target-lang nso --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test --destdir data-bin/ennso\n",
        "\n",
        "!mkdir -p checkpoint/fconv\n",
        "!python train.py data-bin/ennso \\\n",
        "    --lr 0.25 --clip-norm 0.1 --dropout 0.2 --max-tokens 4000 \\\n",
        "    --arch fconv --save-dir checkpoint/fconv\n",
        "\n",
        "# for sentencepiece remove ▁\n",
        "output = %run 'generate.py' data-bin/ennso --path checkpoint/fconv/checkpoint_best.pt --beam 5 --batch-size 128 --remove-bpe --source-lang en --target-lang nso"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LLbt1AO0RjdU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**40k**"
      ]
    },
    {
      "metadata": {
        "id": "Ai9FEflLyNyr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SVKZuJ5KRlRs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('../')\n",
        "!cat fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.en fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.nso > combine.txt\n",
        "!fairseq/subword-nmt/learn_bpe.py -s 40000 <combine.txt> ennso.codes\n",
        "\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.en > train.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.train.nso > train.nso\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.dev.en > valid.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.dev.nso > valid.nso\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.test.en > test.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c ennso.codes < fairseq/ukuxhumana/clean/en_nso/ennso_parallel.test.nso > test.nso\n",
        "\n",
        "os.chdir('fairseq/')\n",
        "TEXT=\"..\"\n",
        "%run 'preprocess.py' --source-lang en --target-lang nso --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test --destdir data-bin/ennso\n",
        "\n",
        "!mkdir -p checkpoint/fconv\n",
        "!python train.py data-bin/ennso \\\n",
        "    --lr 0.25 --clip-norm 0.1 --dropout 0.2 --max-tokens 4000 \\\n",
        "    --arch fconv --save-dir chckpoint/fconv\n",
        "\n",
        "# for sentencepiece remove ▁\n",
        "output = %run 'generate.py' data-bin/ennso --path chckpoint/fconv/checkpoint_best.pt --beam 5 --batch-size 128 --remove-bpe --source-lang en --target-lang nso"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r9LE_5D8X8Zc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Results\n",
        "\n",
        "*   40k: 7.50\n",
        "*   36k: 8.65\n",
        "*   32k: 7.27\n",
        "*   28k: 8.21\n",
        "*   24k: 6.98\n",
        "*   20k: 8.68\n",
        "*   16k: 10.07\n",
        "*   12k: 10.14\n",
        "*     8k: 8.73\n",
        "*     4k: 12.18\n",
        "\n"
      ]
    }
  ]
}