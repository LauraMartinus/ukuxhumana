{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VariousZuluTests.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LauraMartinus/ukuxhumana/blob/master/fairseq/VariousZuluTests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "SkKnSBRPcNAw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports and Data"
      ]
    },
    {
      "metadata": {
        "id": "xJw7gJjAcT3w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Include pytorch"
      ]
    },
    {
      "metadata": {
        "id": "cy4yag-PasRD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4KDha2f1cXCF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Include and install Fairseq"
      ]
    },
    {
      "metadata": {
        "id": "kh2vbuZ6bUPX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3383
        },
        "outputId": "8accbb90-a26e-4e2d-f4dc-c08180dd7f39"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pytorch/fairseq.git\n",
        "import os\n",
        "os.chdir(\"fairseq/\")\n",
        "!pip install -r requirements.txt\n",
        "%run -i 'setup.py' build develop"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 127, done.\u001b[K\n",
            "remote: Counting objects: 100% (127/127), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 3436 (delta 56), reused 72 (delta 32), pack-reused 3309\u001b[K\n",
            "Receiving objects: 100% (3436/3436), 3.34 MiB | 20.34 MiB/s, done.\n",
            "Resolving deltas: 100% (2480/2480), done.\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.11.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.14.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.28.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->-r requirements.txt (line 1)) (2.19)\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "creating build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/sequence_generator.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/multiprocessing_pdb.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/tokenizer.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/bleu.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/options.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/progress_bar.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/trainer.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/legacy_distributed_data_parallel.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/distributed_utils.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/meters.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/__init__.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/search.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/utils.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/sequence_scorer.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "creating build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_sequence_generator.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_average_checkpoints.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_dictionary.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_character_token_embedder.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_utils.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_convtbc.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_binaries.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_train.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_label_smoothing.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_backtranslation_dataset.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_sequence_scorer.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_reproducibility.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/__init__.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_noising.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/utils.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_iterators.py -> build/lib.linux-x86_64-3.6/tests\n",
            "creating build/lib.linux-x86_64-3.6/scripts\n",
            "copying scripts/build_sym_alignment.py -> build/lib.linux-x86_64-3.6/scripts\n",
            "copying scripts/__init__.py -> build/lib.linux-x86_64-3.6/scripts\n",
            "copying scripts/read_binarized.py -> build/lib.linux-x86_64-3.6/scripts\n",
            "copying scripts/average_checkpoints.py -> build/lib.linux-x86_64-3.6/scripts\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy.py -> build/lib.linux-x86_64-3.6/fairseq/criterions\n",
            "copying fairseq/criterions/composite_loss.py -> build/lib.linux-x86_64-3.6/fairseq/criterions\n",
            "copying fairseq/criterions/adaptive_loss.py -> build/lib.linux-x86_64-3.6/fairseq/criterions\n",
            "copying fairseq/criterions/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/criterions\n",
            "copying fairseq/criterions/fairseq_criterion.py -> build/lib.linux-x86_64-3.6/fairseq/criterions\n",
            "copying fairseq/criterions/cross_entropy.py -> build/lib.linux-x86_64-3.6/fairseq/criterions\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/tasks\n",
            "copying fairseq/tasks/language_modeling.py -> build/lib.linux-x86_64-3.6/fairseq/tasks\n",
            "copying fairseq/tasks/multilingual_translation.py -> build/lib.linux-x86_64-3.6/fairseq/tasks\n",
            "copying fairseq/tasks/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/tasks\n",
            "copying fairseq/tasks/translation.py -> build/lib.linux-x86_64-3.6/fairseq/tasks\n",
            "copying fairseq/tasks/fairseq_task.py -> build/lib.linux-x86_64-3.6/fairseq/tasks\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/noising.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/indexed_dataset.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/iterators.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/dictionary.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/token_block_dataset.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/round_robin_zip_datasets.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/data_utils.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/transform_eos_dataset.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/concat_dataset.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/language_pair_dataset.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/monolingual_dataset.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/backtranslation_dataset.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/fairseq_dataset.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/composite_encoder.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/distributed_fairseq_model.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/multilingual_transformer.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/fairseq_model.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/fairseq_encoder.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/lstm.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/transformer.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/lightconv.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/fairseq_decoder.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/fconv_self_att.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/fairseq_incremental_decoder.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/fconv.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "copying fairseq/optim/adam.py -> build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "copying fairseq/optim/fairseq_optimizer.py -> build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "copying fairseq/optim/sgd.py -> build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "copying fairseq/optim/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "copying fairseq/optim/adafactor.py -> build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "copying fairseq/optim/nag.py -> build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "copying fairseq/optim/adagrad.py -> build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "copying fairseq/optim/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/adaptive_input.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/scalar_bias.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/downsampled_multihead_attention.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/grad_multiply.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/conv_tbc.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/linearized_convolution.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/dynamic_convolution.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/multihead_attention.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/highway.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/adaptive_softmax.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/sinusoidal_positional_embedding.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/lightweight_convolution.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/learned_positional_embedding.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/beamable_mm.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/unfold1d.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/character_token_embedder.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/fixed_schedule.py -> build/lib.linux-x86_64-3.6/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/triangular_lr_scheduler.py -> build/lib.linux-x86_64-3.6/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/fairseq_lr_scheduler.py -> build/lib.linux-x86_64-3.6/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/cosine_lr_scheduler.py -> build/lib.linux-x86_64-3.6/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/reduce_lr_on_plateau.py -> build/lib.linux-x86_64-3.6/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/inverse_square_root_schedule.py -> build/lib.linux-x86_64-3.6/fairseq/optim/lr_scheduler\n",
            "running build_ext\n",
            "building 'fairseq.libbleu' extension\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/fairseq\n",
            "creating build/temp.linux-x86_64-3.6/fairseq/clib\n",
            "creating build/temp.linux-x86_64-3.6/fairseq/clib/libbleu\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.6m -c fairseq/clib/libbleu/libbleu.cpp -o build/temp.linux-x86_64-3.6/fairseq/clib/libbleu/libbleu.o -std=c++11\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.6m -c fairseq/clib/libbleu/module.cpp -o build/temp.linux-x86_64-3.6/fairseq/clib/libbleu/module.o -std=c++11\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/fairseq/clib/libbleu/libbleu.o build/temp.linux-x86_64-3.6/fairseq/clib/libbleu/module.o -o build/lib.linux-x86_64-3.6/fairseq/libbleu.cpython-36m-x86_64-linux-gnu.so\n",
            "running develop\n",
            "running egg_info\n",
            "creating fairseq.egg-info\n",
            "writing fairseq.egg-info/PKG-INFO\n",
            "writing dependency_links to fairseq.egg-info/dependency_links.txt\n",
            "writing requirements to fairseq.egg-info/requires.txt\n",
            "writing top-level names to fairseq.egg-info/top_level.txt\n",
            "writing manifest file 'fairseq.egg-info/SOURCES.txt'\n",
            "writing manifest file 'fairseq.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "copying build/lib.linux-x86_64-3.6/fairseq/libbleu.cpython-36m-x86_64-linux-gnu.so -> fairseq\n",
            "Creating /usr/local/lib/python3.6/dist-packages/fairseq.egg-link (link to .)\n",
            "Adding fairseq 0.6.0 to easy-install.pth file\n",
            "\n",
            "Installed /content/fairseq\n",
            "Processing dependencies for fairseq==0.6.0\n",
            "Searching for tqdm==4.28.1\n",
            "Best match: tqdm 4.28.1\n",
            "Adding tqdm 4.28.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for torch==1.0.0\n",
            "Best match: torch 1.0.0\n",
            "Adding torch 1.0.0 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.14.6\n",
            "Best match: numpy 1.14.6\n",
            "Adding numpy 1.14.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for cffi==1.11.5\n",
            "Best match: cffi 1.11.5\n",
            "Adding cffi 1.11.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pycparser==2.19\n",
            "Best match: pycparser 2.19\n",
            "Adding pycparser 2.19 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for fairseq==0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CzzmR9D6ccOm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ukuxhumana repo includes the data needed. Subword provides scripts to do bpe."
      ]
    },
    {
      "metadata": {
        "id": "OpIE-Cg_bYa4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "b99c6859-bd3d-4454-c69b-4e0b4e9b9da7"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/LauraMartinus/ukuxhumana.git\n",
        "!git clone https://github.com/rsennrich/subword-nmt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ukuxhumana'...\n",
            "remote: Enumerating objects: 167, done.\u001b[K\n",
            "remote: Counting objects: 100% (167/167), done.\u001b[K\n",
            "remote: Compressing objects: 100% (140/140), done.\u001b[K\n",
            "remote: Total 1433 (delta 79), reused 77 (delta 27), pack-reused 1266\u001b[K\n",
            "Receiving objects: 100% (1433/1433), 412.20 MiB | 22.94 MiB/s, done.\n",
            "Resolving deltas: 100% (686/686), done.\n",
            "Checking out files: 100% (316/316), done.\n",
            "Cloning into 'subword-nmt'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 509 (delta 14), reused 10 (delta 2), pack-reused 481\u001b[K\n",
            "Receiving objects: 100% (509/509), 216.68 KiB | 4.33 MiB/s, done.\n",
            "Resolving deltas: 100% (301/301), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PWDbDk9Jclyj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training of Various Models"
      ]
    },
    {
      "metadata": {
        "id": "8SOfkO6Gcrzt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Standard Transformer\n",
        "Using clean data, BPE for 4000."
      ]
    },
    {
      "metadata": {
        "id": "90FDwm0Rbab1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4941
        },
        "outputId": "2df0ff38-8683-4cb3-e81b-ced5daf149c0"
      },
      "cell_type": "code",
      "source": [
        "os.chdir('../')\n",
        "!cat fairseq/ukuxhumana/clean/en_zu/enzu_parallel.train.en fairseq/ukuxhumana/clean/en_zu/enzu_parallel.train.zu > combine.txt\n",
        "!fairseq/subword-nmt/learn_bpe.py -s 4000 <combine.txt> enzu.codes\n",
        "\n",
        "!fairseq/subword-nmt/apply_bpe.py -c enzu.codes < fairseq/ukuxhumana/clean/en_zu/enzu_parallel.train.en > train.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c enzu.codes < fairseq/ukuxhumana/clean/en_zu/enzu_parallel.train.zu > train.zu\n",
        "!fairseq/subword-nmt/apply_bpe.py -c enzu.codes < fairseq/ukuxhumana/clean/en_zu/enzu_parallel.dev.en > valid.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c enzu.codes < fairseq/ukuxhumana/clean/en_zu/enzu_parallel.dev.zu > valid.zu\n",
        "!fairseq/subword-nmt/apply_bpe.py -c enzu.codes < fairseq/ukuxhumana/clean/en_zu/enzu_parallel.test.en > test.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c enzu.codes < fairseq/ukuxhumana/clean/en_zu/enzu_parallel.test.zu > test.zu\n",
        "\n",
        "os.chdir('fairseq/')\n",
        "TEXT=\"..\"\n",
        "%run 'preprocess.py' --source-lang en --target-lang zu --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test --destdir data-bin/enzu\n",
        "\n",
        "!mkdir -p chckpoint/transformer\n",
        "!python train.py data-bin/enzu \\\n",
        "  -a transformer_iwslt_de_en --optimizer adam --lr 0.0005 -s en -t zu \\\n",
        "  --label-smoothing 0.1 --dropout 0.3 --max-tokens 4000 \\\n",
        "  --min-lr '1e-09' --lr-scheduler inverse_sqrt --weight-decay 0.0001 \\\n",
        "  --criterion label_smoothed_cross_entropy --max-update 50000 \\\n",
        "  --warmup-updates 4000 --warmup-init-lr '1e-07' \\\n",
        "  --adam-betas '(0.9, 0.98)' --save-dir checkpoints/transformer\n",
        "\n",
        "# for sentencepiece remove ▁\n",
        "output = %run 'generate.py' data-bin/enzu --path checkpoints/transformer/checkpoint_best.pt --beam 5 --batch-size 128 --remove-bpe --source-lang en --target-lang zu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fairseq/subword-nmt/learn_bpe.py:267: DeprecationWarning: this script's location has moved to /content/fairseq/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "fairseq/subword-nmt/apply_bpe.py:334: DeprecationWarning: this script's location has moved to /content/fairseq/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "fairseq/subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='enzu.codes' mode='r' encoding='UTF-8'>\n",
            "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
            "fairseq/subword-nmt/apply_bpe.py:334: DeprecationWarning: this script's location has moved to /content/fairseq/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "fairseq/subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='enzu.codes' mode='r' encoding='UTF-8'>\n",
            "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
            "fairseq/subword-nmt/apply_bpe.py:334: DeprecationWarning: this script's location has moved to /content/fairseq/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "fairseq/subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='enzu.codes' mode='r' encoding='UTF-8'>\n",
            "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
            "fairseq/subword-nmt/apply_bpe.py:334: DeprecationWarning: this script's location has moved to /content/fairseq/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "fairseq/subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='enzu.codes' mode='r' encoding='UTF-8'>\n",
            "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
            "fairseq/subword-nmt/apply_bpe.py:334: DeprecationWarning: this script's location has moved to /content/fairseq/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "fairseq/subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='enzu.codes' mode='r' encoding='UTF-8'>\n",
            "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
            "fairseq/subword-nmt/apply_bpe.py:334: DeprecationWarning: this script's location has moved to /content/fairseq/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "fairseq/subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='enzu.codes' mode='r' encoding='UTF-8'>\n",
            "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
            "Namespace(alignfile=None, destdir='data-bin/enzu', joined_dictionary=False, nwordssrc=-1, nwordstgt=-1, only_source=False, output_format='binary', padding_factor=8, source_lang='en', srcdict=None, target_lang='zu', testpref='../test', tgtdict=None, thresholdsrc=0, thresholdtgt=0, trainpref='../train', validpref='../valid', workers=1)\n",
            "| [en] Dictionary: 2815 types\n",
            "| [en] ../train.en: 18709 sents, 560912 tokens, 0.0% replaced by <unk>\n",
            "| [en] Dictionary: 2815 types\n",
            "| [en] ../valid.en: 5019 sents, 162767 tokens, 0.0166% replaced by <unk>\n",
            "| [en] Dictionary: 2815 types\n",
            "| [en] ../test.en: 3000 sents, 106897 tokens, 0.0178% replaced by <unk>\n",
            "| [zu] Dictionary: 3615 types\n",
            "| [zu] ../train.zu: 18709 sents, 587524 tokens, 0.0% replaced by <unk>\n",
            "| [zu] Dictionary: 3615 types\n",
            "| [zu] ../valid.zu: 5019 sents, 173777 tokens, 0.015% replaced by <unk>\n",
            "| [zu] Dictionary: 3615 types\n",
            "| [zu] ../test.zu: 3000 sents, 115600 tokens, 0.0363% replaced by <unk>\n",
            "| Wrote preprocessed data to data-bin/enzu\n",
            "Namespace(adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='transformer_iwslt_de_en', attention_dropout=0.0, bucket_cap_mb=25, clip_norm=25, cpu=False, criterion='label_smoothed_cross_entropy', data=['data-bin/enzu'], ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layers=6, encoder_learned_pos=False, encoder_normalize_before=False, fix_batches_to_gpus=False, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, lazy_load=False, left_pad_source='True', left_pad_target='False', log_format=None, log_interval=1000, lr=[0.0005], lr_scheduler='inverse_sqrt', lr_shrink=0.1, max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=4000, max_update=50000, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, momentum=0.99, no_epoch_checkpoints=False, no_progress_bar=False, no_save=False, no_token_positional_embeddings=False, num_workers=0, optimizer='adam', optimizer_overrides='{}', raw_text=False, relu_dropout=0.0, reset_lr_scheduler=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/transformer', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='en', target_lang='zu', task='translation', train_subset='train', update_freq=[1], upsample_primary=1, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0001)\n",
            "| [en] dictionary: 2816 types\n",
            "| [zu] dictionary: 3616 types\n",
            "| data-bin/enzu train 18709 examples\n",
            "| data-bin/enzu valid 5019 examples\n",
            "TransformerModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embed_tokens): Embedding(2816, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "        (layer_norms): ModuleList(\n",
            "          (0): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "        (layer_norms): ModuleList(\n",
            "          (0): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "        (layer_norms): ModuleList(\n",
            "          (0): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "        (layer_norms): ModuleList(\n",
            "          (0): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "        (layer_norms): ModuleList(\n",
            "          (0): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "        (layer_norms): ModuleList(\n",
            "          (0): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embed_tokens): Embedding(3616, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "| model transformer_iwslt_de_en, criterion LabelSmoothedCrossEntropyCriterion\n",
            "| num. model params: 36687872 (num. trained: 36687872)\n",
            "| training on 1 GPUs\n",
            "| max tokens per GPU = 4000 and max sentences per GPU = None\n",
            "| no existing checkpoint found checkpoints/transformer/checkpoint_last.pt\n",
            "| epoch 001 | loss 11.473 | nll_loss 11.356 | ppl 2621.15 | wps 5328 | ups 1.8 | wpb 2909 | bsz 93 | num_updates 202 | lr 2.5345e-05 | gnorm 1.752 | clip 0% | oom 0 | wall 111 | train_wall 108\n",
            "| epoch 001 | valid on 'valid' subset | valid_loss 10.6039 | valid_nll_loss 10.3777 | valid_ppl 1330.49 | num_updates 202\n",
            "| epoch 002 | loss 10.443 | nll_loss 10.175 | ppl 1155.81 | wps 5340 | ups 1.5 | wpb 2909 | bsz 93 | num_updates 404 | lr 5.05899e-05 | gnorm 1.237 | clip 0% | oom 0 | wall 242 | train_wall 216\n",
            "| epoch 002 | valid on 'valid' subset | valid_loss 10.2107 | valid_nll_loss 9.86966 | valid_ppl 935.54 | num_updates 404 | best 10.2107\n",
            "| epoch 003 | loss 10.218 | nll_loss 9.892 | ppl 950.04 | wps 5353 | ups 1.5 | wpb 2909 | bsz 93 | num_updates 606 | lr 7.58349e-05 | gnorm 1.043 | clip 0% | oom 0 | wall 373 | train_wall 324\n",
            "| epoch 003 | valid on 'valid' subset | valid_loss 10.141 | valid_nll_loss 9.78398 | valid_ppl 881.60 | num_updates 606 | best 10.141\n",
            "| epoch 004 | loss 10.084 | nll_loss 9.736 | ppl 852.97 | wps 5318 | ups 1.5 | wpb 2909 | bsz 93 | num_updates 808 | lr 0.00010108 | gnorm 1.194 | clip 0% | oom 0 | wall 505 | train_wall 432\n",
            "| epoch 004 | valid on 'valid' subset | valid_loss 9.80766 | valid_nll_loss 9.40328 | valid_ppl 677.13 | num_updates 808 | best 9.80766\n",
            "| epoch 005 | loss 9.695 | nll_loss 9.282 | ppl 622.47 | wps 5316 | ups 1.5 | wpb 2909 | bsz 93 | num_updates 1010 | lr 0.000126325 | gnorm 1.250 | clip 0% | oom 0 | wall 637 | train_wall 540\n",
            "| epoch 005 | valid on 'valid' subset | valid_loss 9.4099 | valid_nll_loss 8.92806 | valid_ppl 487.09 | num_updates 1010 | best 9.4099\n",
            "| epoch 006 | loss 9.328 | nll_loss 8.844 | ppl 459.60 | wps 5307 | ups 1.5 | wpb 2909 | bsz 93 | num_updates 1212 | lr 0.00015157 | gnorm 1.449 | clip 0% | oom 0 | wall 768 | train_wall 649\n",
            "| epoch 006 | valid on 'valid' subset | valid_loss 9.03248 | valid_nll_loss 8.45877 | valid_ppl 351.84 | num_updates 1212 | best 9.03248\n",
            "| epoch 007 | loss 8.900 | nll_loss 8.343 | ppl 324.82 | wps 5300 | ups 1.5 | wpb 2909 | bsz 93 | num_updates 1414 | lr 0.000176815 | gnorm 1.549 | clip 0% | oom 0 | wall 900 | train_wall 757\n",
            "| epoch 007 | valid on 'valid' subset | valid_loss 8.56102 | valid_nll_loss 7.90899 | valid_ppl 240.35 | num_updates 1414 | best 8.56102\n",
            "| epoch 008 | loss 8.451 | nll_loss 7.821 | ppl 226.05 | wps 5290 | ups 1.5 | wpb 2909 | bsz 93 | num_updates 1616 | lr 0.00020206 | gnorm 1.660 | clip 0% | oom 0 | wall 1032 | train_wall 866\n",
            "| epoch 008 | valid on 'valid' subset | valid_loss 8.21479 | valid_nll_loss 7.49281 | valid_ppl 180.12 | num_updates 1616 | best 8.21479\n",
            "| epoch 009 | loss 8.069 | nll_loss 7.373 | ppl 165.80 | wps 5308 | ups 1.5 | wpb 2909 | bsz 93 | num_updates 1818 | lr 0.000227305 | gnorm 1.655 | clip 0% | oom 0 | wall 1164 | train_wall 974\n",
            "| epoch 009 | valid on 'valid' subset | valid_loss 8.01214 | valid_nll_loss 7.22481 | valid_ppl 149.58 | num_updates 1818 | best 8.01214\n",
            "| epoch 010 | loss 7.786 | nll_loss 7.039 | ppl 131.55 | wps 5319 | ups 1.5 | wpb 2909 | bsz 93 | num_updates 2020 | lr 0.00025255 | gnorm 1.605 | clip 0% | oom 0 | wall 1295 | train_wall 1082\n",
            "| epoch 010 | valid on 'valid' subset | valid_loss 7.8132 | valid_nll_loss 6.97726 | valid_ppl 126.00 | num_updates 2020 | best 7.8132\n",
            "| epoch 011 | loss 7.574 | nll_loss 6.790 | ppl 110.62 | wps 5310 | ups 1.5 | wpb 2909 | bsz 93 | num_updates 2222 | lr 0.000277794 | gnorm 1.583 | clip 0% | oom 0 | wall 1427 | train_wall 1191\n",
            "| epoch 011 | valid on 'valid' subset | valid_loss 7.69517 | valid_nll_loss 6.83291 | valid_ppl 114.00 | num_updates 2222 | best 7.69517\n",
            "| epoch 012 | loss 7.381 | nll_loss 6.564 | ppl 94.61 | wps 5298 | ups 1.5 | wpb 2909 | bsz 93 | num_updates 2424 | lr 0.000303039 | gnorm 1.522 | clip 0% | oom 0 | wall 1558 | train_wall 1299\n",
            "| epoch 012 | valid on 'valid' subset | valid_loss 7.59416 | valid_nll_loss 6.70268 | valid_ppl 104.16 | num_updates 2424 | best 7.59416\n",
            "| epoch 013 | loss 7.217 | nll_loss 6.371 | ppl 82.78 | wps 5302 | ups 1.5 | wpb 2909 | bsz 93 | num_updates 2626 | lr 0.000328284 | gnorm 1.521 | clip 0% | oom 0 | wall 1690 | train_wall 1408\n",
            "| epoch 013 | valid on 'valid' subset | valid_loss 7.53556 | valid_nll_loss 6.63474 | valid_ppl 99.37 | num_updates 2626 | best 7.53556\n",
            "| epoch 014 | loss 7.069 | nll_loss 6.199 | ppl 73.46 | wps 5314 | ups 1.5 | wpb 2909 | bsz 93 | num_updates 2828 | lr 0.000353529 | gnorm 1.474 | clip 0% | oom 0 | wall 1822 | train_wall 1516\n",
            "| epoch 014 | valid on 'valid' subset | valid_loss 7.44566 | valid_nll_loss 6.51443 | valid_ppl 91.42 | num_updates 2828 | best 7.44566\n",
            "| epoch 015 | loss 6.934 | nll_loss 6.042 | ppl 65.88 | wps 5286 | ups 1.5 | wpb 2909 | bsz 93 | num_updates 3030 | lr 0.000378774 | gnorm 1.446 | clip 0% | oom 0 | wall 1954 | train_wall 1625\n",
            "| epoch 015 | valid on 'valid' subset | valid_loss 7.35392 | valid_nll_loss 6.41665 | valid_ppl 85.43 | num_updates 3030 | best 7.35392\n",
            "| epoch 016 | loss 6.812 | nll_loss 5.899 | ppl 59.68 | wps 5304 | ups 1.5 | wpb 2909 | bsz 93 | num_updates 3232 | lr 0.000404019 | gnorm 1.460 | clip 0% | oom 0 | wall 2086 | train_wall 1733\n",
            "| epoch 016 | valid on 'valid' subset | valid_loss 7.2606 | valid_nll_loss 6.30578 | valid_ppl 79.11 | num_updates 3232 | best 7.2606\n",
            "| epoch 017 | loss 6.685 | nll_loss 5.752 | ppl 53.88 | wps 5296 | ups 1.5 | wpb 2909 | bsz 93 | num_updates 3434 | lr 0.000429264 | gnorm 1.429 | clip 0% | oom 0 | wall 2218 | train_wall 1841\n",
            "| epoch 017 | valid on 'valid' subset | valid_loss 7.26374 | valid_nll_loss 6.29705 | valid_ppl 78.63 | num_updates 3434 | best 7.2606\n",
            "| epoch 018 | loss 6.579 | nll_loss 5.628 | ppl 49.46 | wps 5298 | ups 1.6 | wpb 2909 | bsz 93 | num_updates 3636 | lr 0.000454509 | gnorm 1.413 | clip 0% | oom 0 | wall 2347 | train_wall 1950\n",
            "| epoch 018 | valid on 'valid' subset | valid_loss 7.22716 | valid_nll_loss 6.24998 | valid_ppl 76.11 | num_updates 3636 | best 7.22716\n",
            "| epoch 019 | loss 6.474 | nll_loss 5.507 | ppl 45.47 | wps 5318 | ups 1.5 | wpb 2909 | bsz 93 | num_updates 3838 | lr 0.000479754 | gnorm 1.399 | clip 0% | oom 0 | wall 2479 | train_wall 2058\n",
            "| epoch 019 | valid on 'valid' subset | valid_loss 7.26089 | valid_nll_loss 6.27735 | valid_ppl 77.57 | num_updates 3838 | best 7.22716\n",
            "| epoch 020 | loss 6.363 | nll_loss 5.377 | ppl 41.57 | wps 5297 | ups 1.6 | wpb 2909 | bsz 93 | num_updates 4040 | lr 0.000497519 | gnorm 1.335 | clip 0% | oom 0 | wall 2608 | train_wall 2167\n",
            "| epoch 020 | valid on 'valid' subset | valid_loss 7.21796 | valid_nll_loss 6.2216 | valid_ppl 74.63 | num_updates 4040 | best 7.21796\n",
            "| epoch 021 | loss 6.272 | nll_loss 5.270 | ppl 38.58 | wps 5303 | ups 1.5 | wpb 2909 | bsz 93 | num_updates 4242 | lr 0.000485528 | gnorm 1.367 | clip 0% | oom 0 | wall 2740 | train_wall 2275\n",
            "| epoch 021 | valid on 'valid' subset | valid_loss 7.18938 | valid_nll_loss 6.18187 | valid_ppl 72.60 | num_updates 4242 | best 7.18938\n",
            "| epoch 022 | loss 6.155 | nll_loss 5.135 | ppl 35.14 | wps 5330 | ups 1.5 | wpb 2909 | bsz 93 | num_updates 4444 | lr 0.000474365 | gnorm 1.325 | clip 0% | oom 0 | wall 2871 | train_wall 2383\n",
            "| epoch 022 | valid on 'valid' subset | valid_loss 7.19327 | valid_nll_loss 6.1816 | valid_ppl 72.58 | num_updates 4444 | best 7.18938\n",
            "| epoch 023 | loss 6.051 | nll_loss 5.014 | ppl 32.31 | wps 5339 | ups 1.6 | wpb 2909 | bsz 93 | num_updates 4646 | lr 0.000463938 | gnorm 1.322 | clip 0% | oom 0 | wall 2999 | train_wall 2491\n",
            "| epoch 023 | valid on 'valid' subset | valid_loss 7.21672 | valid_nll_loss 6.19748 | valid_ppl 73.39 | num_updates 4646 | best 7.18938\n",
            "| epoch 024 | loss 5.947 | nll_loss 4.892 | ppl 29.69 | wps 5338 | ups 1.6 | wpb 2909 | bsz 93 | num_updates 4848 | lr 0.00045417 | gnorm 1.306 | clip 0% | oom 0 | wall 3127 | train_wall 2599\n",
            "| epoch 024 | valid on 'valid' subset | valid_loss 7.21596 | valid_nll_loss 6.18873 | valid_ppl 72.94 | num_updates 4848 | best 7.18938\n",
            "| epoch 025 | loss 5.842 | nll_loss 4.769 | ppl 27.26 | wps 5330 | ups 1.6 | wpb 2909 | bsz 93 | num_updates 5050 | lr 0.000444994 | gnorm 1.276 | clip 0% | oom 0 | wall 3256 | train_wall 2707\n",
            "| epoch 025 | valid on 'valid' subset | valid_loss 7.26182 | valid_nll_loss 6.23309 | valid_ppl 75.22 | num_updates 5050 | best 7.18938\n",
            "| epoch 026 | loss 5.760 | nll_loss 4.671 | ppl 25.48 | wps 5335 | ups 1.6 | wpb 2909 | bsz 93 | num_updates 5252 | lr 0.000436353 | gnorm 1.306 | clip 0% | oom 0 | wall 3384 | train_wall 2815\n",
            "| epoch 026 | valid on 'valid' subset | valid_loss 7.27165 | valid_nll_loss 6.23281 | valid_ppl 75.21 | num_updates 5252 | best 7.18938\n",
            "| epoch 027 | loss 5.666 | nll_loss 4.562 | ppl 23.62 | wps 5316 | ups 1.6 | wpb 2909 | bsz 93 | num_updates 5454 | lr 0.000428196 | gnorm 1.279 | clip 0% | oom 0 | wall 3512 | train_wall 2923\n",
            "| epoch 027 | valid on 'valid' subset | valid_loss 7.3844 | valid_nll_loss 6.35228 | valid_ppl 81.70 | num_updates 5454 | best 7.18938\n",
            "| epoch 028 | loss 5.588 | nll_loss 4.469 | ppl 22.14 | wps 5333 | ups 1.6 | wpb 2909 | bsz 93 | num_updates 5656 | lr 0.00042048 | gnorm 1.281 | clip 0% | oom 0 | wall 3640 | train_wall 3031\n",
            "| epoch 028 | valid on 'valid' subset | valid_loss 7.26229 | valid_nll_loss 6.21714 | valid_ppl 74.40 | num_updates 5656 | best 7.18938\n",
            "| epoch 029 | loss 5.499 | nll_loss 4.364 | ppl 20.59 | wps 5336 | ups 1.6 | wpb 2909 | bsz 93 | num_updates 5858 | lr 0.000413167 | gnorm 1.269 | clip 0% | oom 0 | wall 3768 | train_wall 3139\n",
            "| epoch 029 | valid on 'valid' subset | valid_loss 7.28935 | valid_nll_loss 6.24032 | valid_ppl 75.60 | num_updates 5858 | best 7.18938\n",
            "| epoch 030 | loss 5.446 | nll_loss 4.299 | ppl 19.69 | wps 5338 | ups 1.6 | wpb 2909 | bsz 93 | num_updates 6060 | lr 0.000406222 | gnorm 1.323 | clip 0% | oom 0 | wall 3896 | train_wall 3247\n",
            "| epoch 030 | valid on 'valid' subset | valid_loss 7.32752 | valid_nll_loss 6.27265 | valid_ppl 77.31 | num_updates 6060 | best 7.18938\n",
            "| epoch 031:  39% 79/202 [00:43<01:11,  1.71it/s, loss=5.268, nll_loss=4.096, ppl=17.10, wps=5398, ups=1.3, wpb=2940, bsz=97, num_updates=6139, lr=0.0004036, gnorm=1.288, clip=0%, oom=0, wall=3958, train_wall=3289]  "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WhDXhSX2m_di",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10045
        },
        "outputId": "483a569e-6051-427b-b1b7-3e499ce291da"
      },
      "cell_type": "code",
      "source": [
        "# os.chdir('fairseq/')\n",
        "# TEXT=\"..\"\n",
        "# %run 'preprocess.py' --source-lang en --target-lang zu --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test --destdir data-bin/enzu\n",
        "\n",
        "!mkdir -p chckpoint/transformer\n",
        "!python train.py data-bin/enzu --lr 0.25 --clip-norm 0.1 --dropout 0.2 --max-tokens 200 --arch transformer --save-dir chckpoint/transformr \n",
        "    #--lr 0.25 --clip-norm 0.1 --dropout 0.2 --max-tokens 4000 \\\n",
        "    #--arch transformer --save-dir checkpoint/transformer\n",
        "\n",
        "# for sentencepiece remove ▁\n",
        "output = %run 'generate.py' data-bin/enzu --path chckpoint/transformr/checkpoint_best.pt --beam 5 --batch-size 128 --remove-bpe --source-lang en --target-lang zu"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='transformer', attention_dropout=0.0, bucket_cap_mb=25, clip_norm=0.1, cpu=False, criterion='cross_entropy', data=['data-bin/enzu'], ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.2, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_learned_pos=False, encoder_normalize_before=False, fix_batches_to_gpus=False, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, lazy_load=False, left_pad_source='True', left_pad_target='False', log_format=None, log_interval=1000, lr=[0.25], lr_scheduler='reduce_lr_on_plateau', lr_shrink=0.1, max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=200, max_update=0, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-05, momentum=0.99, no_epoch_checkpoints=False, no_progress_bar=False, no_save=False, no_token_positional_embeddings=False, num_workers=0, optimizer='nag', optimizer_overrides='{}', raw_text=False, relu_dropout=0.0, reset_lr_scheduler=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='chckpoint/transformr', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation', train_subset='train', update_freq=[1], upsample_primary=1, user_dir=None, valid_subset='valid', validate_interval=1, weight_decay=0.0)\n",
            "| [en] dictionary: 2816 types\n",
            "| [zu] dictionary: 3616 types\n",
            "| data-bin/enzu train 18709 examples\n",
            "| data-bin/enzu valid 5019 examples\n",
            "TransformerModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embed_tokens): Embedding(2816, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (layer_norms): ModuleList(\n",
            "          (0): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (layer_norms): ModuleList(\n",
            "          (0): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (layer_norms): ModuleList(\n",
            "          (0): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (layer_norms): ModuleList(\n",
            "          (0): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (layer_norms): ModuleList(\n",
            "          (0): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (layer_norms): ModuleList(\n",
            "          (0): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "          (1): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embed_tokens): Embedding(3616, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "| model transformer, criterion CrossEntropyCriterion\n",
            "| num. model params: 49283072 (num. trained: 49283072)\n",
            "| training on 1 GPUs\n",
            "| max tokens per GPU = 200 and max sentences per GPU = None\n",
            "| no existing checkpoint found chckpoint/transformr/checkpoint_last.pt\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "| epoch 001:   0% 0/3561 [00:00<?, ?it/s]| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "| WARNING: ran out of memory, skipping batch\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 196, in train_step\n",
            "    ignore_grad\n",
            "  File \"/content/fairseq/fairseq/tasks/fairseq_task.py\", line 173, in train_step\n",
            "    loss, sample_size, logging_output = criterion(model, sample)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/criterions/cross_entropy.py\", line 30, in forward\n",
            "    net_output = model(**sample['net_input'])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/models/fairseq_model.py\", line 179, in forward\n",
            "    decoder_out = self.decoder(prev_output_tokens, encoder_out)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/models/transformer.py\", line 500, in forward\n",
            "    self_attn_mask=self.buffered_future_mask(x) if incremental_state is None else None,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/models/transformer.py\", line 708, in forward\n",
            "    attn_mask=self_attn_mask,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/modules/multihead_attention.py\", line 96, in forward\n",
            "    q, k, v = self.in_proj_qkv(query)\n",
            "  File \"/content/fairseq/fairseq/modules/multihead_attention.py\", line 210, in in_proj_qkv\n",
            "    return self._in_proj(query).chunk(3, dim=-1)\n",
            "  File \"/content/fairseq/fairseq/modules/multihead_attention.py\", line 230, in _in_proj\n",
            "    return F.linear(input, weight, bias)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\", line 1354, in linear\n",
            "    output = input.matmul(weight.t())\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 1024.00 KiB (GPU 0; 11.17 GiB total capacity; 453.34 MiB already allocated; 576.00 KiB free; 417.50 KiB cached)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 414, in <module>\n",
            "    main(args)\n",
            "  File \"train.py\", line 100, in main\n",
            "    train(args, trainer, task, epoch_itr)\n",
            "  File \"train.py\", line 135, in train\n",
            "    log_output = trainer.train_step(samples)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 211, in train_step\n",
            "    self.handle_ooms(ooms)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 355, in handle_ooms\n",
            "    self.train_step([self._oom_batch], True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 196, in train_step\n",
            "    ignore_grad\n",
            "KeyboardInterrupt\n",
            "Namespace(beam=5, cpu=False, data=['data-bin/enzu'], diverse_beam_groups=-1, diverse_beam_strength=0.5, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', lazy_load=False, left_pad_source='True', left_pad_target='False', lenpen=1, log_format=None, log_interval=1000, match_source_len=False, max_len_a=0, max_len_b=200, max_sentences=128, max_source_positions=1024, max_target_positions=1024, max_tokens=None, memory_efficient_fp16=False, min_len=1, model_overrides='{}', nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, num_shards=1, num_workers=0, path='chckpoint/transformr/checkpoint_best.pt', prefix_size=0, print_alignment=False, quiet=False, raw_text=False, remove_bpe='@@ ', replace_unk=None, sampling=False, sampling_temperature=1, sampling_topk=-1, score_reference=False, seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, source_lang='en', target_lang='zu', task='translation', unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None)\n",
            "| [en] dictionary: 2816 types\n",
            "| [zu] dictionary: 3616 types\n",
            "| data-bin/enzu test 3000 examples\n",
            "| ['data-bin/enzu'] test 3000 examples\n",
            "| loading model(s) from chckpoint/transformr/checkpoint_best.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/content/fairseq/generate.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_generation_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args_and_arch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/fairseq/generate.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'| loading model(s) from {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     models, _model_args = utils.load_ensemble_for_inference(\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_arg_overrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_overrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     )\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/fairseq/fairseq/utils.py\u001b[0m in \u001b[0;36mload_ensemble_for_inference\u001b[0;34m(filenames, task, model_arg_overrides)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model file not found: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_checkpoint_to_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Model file not found: chckpoint/transformr/checkpoint_best.pt"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "cDBW6CDVju4h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dJ9xhsJ4i5AW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b7e8d98b-aa6a-45d7-d337-21130bd415f2"
      },
      "cell_type": "code",
      "source": [
        "# Average 10 latest checkpoints:\n",
        "!python scripts/average_checkpoints.py --inputs checkpoint/fconv/ \\\n",
        "   --num-epoch-checkpoints 4 --output checkpoint/fconv/model.pt"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(checkpoint_upper_bound=None, inputs=['checkpoint/fconv/'], num_epoch_checkpoints=4, num_update_checkpoints=None, output='checkpoint/fconv/model.pt')\n",
            "averaging checkpoints:  ['checkpoint/fconv/checkpoint8.pt', 'checkpoint/fconv/checkpoint7.pt', 'checkpoint/fconv/checkpoint6.pt', 'checkpoint/fconv/checkpoint5.pt']\n",
            "Finished writing averaged checkpoint to checkpoint/fconv/model.pt.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QzXitdDJj6AH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9855
        },
        "outputId": "6a2984ae-b28c-47cb-a4a3-627703198e20"
      },
      "cell_type": "code",
      "source": [
        "!python generate.py data-bin/enzu \\\n",
        "  --path checkpoint/fconv/model.pt \\\n",
        "  --batch-size 128 --beam 5 --remove-bpe"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(beam=5, cpu=False, data=['data-bin/enzu'], diverse_beam_groups=-1, diverse_beam_strength=0.5, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', lazy_load=False, left_pad_source='True', left_pad_target='False', lenpen=1, log_format=None, log_interval=1000, match_source_len=False, max_len_a=0, max_len_b=200, max_sentences=128, max_source_positions=1024, max_target_positions=1024, max_tokens=None, memory_efficient_fp16=False, min_len=1, model_overrides='{}', nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, num_shards=1, num_workers=0, path='checkpoint/fconv/model.pt', prefix_size=0, print_alignment=False, quiet=False, raw_text=False, remove_bpe='@@ ', replace_unk=None, sampling=False, sampling_temperature=1, sampling_topk=-1, score_reference=False, seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation', unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None)\n",
            "| [en] dictionary: 2816 types\n",
            "| [zu] dictionary: 3616 types\n",
            "| data-bin/enzu test 3000 examples\n",
            "| ['data-bin/enzu'] test 3000 examples\n",
            "| loading model(s) from checkpoint/fconv/model.pt\n",
            "  0% 0/24 [00:00<?, ?it/s]S-2142\tor R1 000 000 .\n",
            "T-2142\tnoma u-R1 000 000 .\n",
            "H-2142\t-3.533318042755127\t.\n",
            "P-2142\t-3.6354 -3.4313\n",
            "S-803\teducation management and information systems\n",
            "T-803\tNokuphathwa kwemfundo kanye nezinhlelo zolwazi\n",
            "H-803\t-3.5333170890808105\t.\n",
            "P-803\t-3.6354 -3.4313\n",
            "S-1580\tLANGTAG\n",
            "T-1580\tLANGTAG\n",
            "H-1580\t-3.5333170890808105\t.\n",
            "P-1580\t-3.6354 -3.4313\n",
            "S-1619\tLanguage equity\n",
            "T-1619\tukulinganisa ulimi\n",
            "H-1619\t-3.533317804336548\t.\n",
            "P-1619\t-3.6354 -3.4313\n",
            "S-875\tIn this regard we will ;\n",
            "T-875\tNgale ndlela:\n",
            "H-875\t-3.5333173274993896\t.\n",
            "P-875\t-3.6354 -3.4313\n",
            "S-1733\tother than on property referred to\n",
            "T-1733\tngaphandle kwezakhiwo ezibalul-\n",
            "H-1733\t-3.5333173274993896\t.\n",
            "P-1733\t-3.6354 -3.4313\n",
            "S-1534\tLanguage units\n",
            "T-1534\tamayunithi olimi\n",
            "H-1534\t-3.5333170890808105\t.\n",
            "P-1534\t-3.6354 -3.4313\n",
            "S-2162\tHindering administration of Act\n",
            "T-2162\tUkuthiya ukusetshenziswa koMthetho\n",
            "H-2162\t-3.5333173274993896\t.\n",
            "P-2162\t-3.6354 -3.4313\n",
            "S-1459\tLegislative context\n",
            "T-1459\tIngqikithi Yezomthetho\n",
            "H-1459\t-3.5333163738250732\t.\n",
            "P-1459\t-3.6354 -3.4313\n",
            "S-2596\tAdministrative fines\n",
            "T-2596\tIzinhlawulo kubaphathi\n",
            "H-2596\t-3.5333175659179688\t.\n",
            "P-2596\t-3.6354 -3.4313\n",
            "S-193\temail address below:\n",
            "T-193\tmail kuleli kheli elilandelayo:\n",
            "H-193\t-3.533317804336548\t.\n",
            "P-193\t-3.6354 -3.4313\n",
            "S-2205\tVicarious liability\n",
            "T-2205\tUkuthwala amacala abanye\n",
            "H-2205\t-3.5333173274993896\t.\n",
            "P-2205\t-3.6354 -3.4313\n",
            "S-991\tV I S I O N\n",
            "T-991\tUMBONO\n",
            "H-991\t-3.533317804336548\t.\n",
            "P-991\t-3.6354 -3.4313\n",
            "S-2706\tInterim relief 20\n",
            "T-2706\tUsizo lwesikhashana\n",
            "H-2706\t-3.5333175659179688\t.\n",
            "P-2706\t-3.6354 -3.4313\n",
            "S-1642\tLanguage equality\n",
            "T-1642\tukulinganisa ulimi\n",
            "H-1642\t-3.5333175659179688\t.\n",
            "P-1642\t-3.6354 -3.4313\n",
            "S-1636\tBilingualism\n",
            "T-1636\tubulimimbili\n",
            "H-1636\t-3.5333175659179688\t.\n",
            "P-1636\t-3.6354 -3.4313\n",
            "S-989\tProfessionalism\n",
            "T-989\tUbungcweti\n",
            "H-989\t-3.5333173274993896\t.\n",
            "P-989\t-3.6354 -3.4313\n",
            "S-1662\tMachine translation\n",
            "T-1662\tizichazamagama\n",
            "H-1662\t-3.5333175659179688\t.\n",
            "P-1662\t-3.6354 -3.4313\n",
            "S-2657\tTransitional provisions\n",
            "T-2657\tImithetho yokwenziwa kwezinguquko\n",
            "H-2657\t-3.5333166122436523\t.\n",
            "P-2657\t-3.6354 -3.4313\n",
            "S-2668\tPenalties 15\n",
            "T-2668\tIzinhlawulo\n",
            "H-2668\t-3.533317804336548\t.\n",
            "P-2668\t-3.6354 -3.4313\n",
            "S-326\tEmpowerment initiatives\n",
            "T-326\tImizamo yokunika abantu amandla\n",
            "H-326\t-3.533318042755127\t.\n",
            "P-326\t-3.6354 -3.4313\n",
            "S-628\tAll beneficiaries of the\n",
            "T-628\tBonke abathola izindlu kula-\n",
            "H-628\t-3.5333170890808105\t.\n",
            "P-628\t-3.6354 -3.4313\n",
            "S-1900\tThreshold determination\n",
            "T-1900\tUkunquma isilinganiso\n",
            "H-1900\t-3.5333175659179688\t.\n",
            "P-1900\t-3.6354 -3.4313\n",
            "S-1883\tUnconscionable conduct\n",
            "T-1883\tUkuziphatha kokungabi nanembeza\n",
            "H-1883\t-3.5333173274993896\t.\n",
            "P-1883\t-3.6354 -3.4313\n",
            "S-272\tnectors for use on self\n",
            "T-272\tnectors azosetshenziswa kwi self-\n",
            "H-272\t-3.5333175659179688\t.\n",
            "P-272\t-3.6354 -3.4313\n",
            "S-1865\tSales records\n",
            "T-1865\tAmarekhodi ezentengiselwano\n",
            "H-1865\t-3.5333175659179688\t.\n",
            "P-1865\t-3.6354 -3.4313\n",
            "S-212\tGeneral: 300\n",
            "T-212\tEminye: 300 2424 .\n",
            "H-212\t-3.5333173274993896\t.\n",
            "P-212\t-3.6354 -3.4313\n",
            "S-1932\tor any international organisation ;\n",
            "T-1932\tnoma noma iyiphi inhlangano yomhlaba wonke ;\n",
            "H-1932\t-3.533318042755127\t.\n",
            "P-1932\t-3.6354 -3.4313\n",
            "S-1711\tTENDERS\n",
            "T-1711\tAMATHENDA\n",
            "H-1711\t-3.5333175659179688\t.\n",
            "P-1711\t-3.6354 -3.4313\n",
            "S-1675\tFriday , 2005\n",
            "T-1675\tngoLwesihlanu , 2005-\n",
            "H-1675\t-3.5333170890808105\t.\n",
            "P-1675\t-3.6354 -3.4313\n",
            "S-934\tSaturdays:\n",
            "T-934\tNgeMigqibelo:\n",
            "H-934\t-3.5333175659179688\t.\n",
            "P-934\t-3.6354 -3.4313\n",
            "S-2278\tAmendment of laws\n",
            "T-2278\tUkuchitshiyelwa kwemithetho\n",
            "H-2278\t-3.5333175659179688\t.\n",
            "P-2278\t-3.6354 -3.4313\n",
            "S-2623\tInvestigation by Commission\n",
            "T-2623\tUphenyo olwenziwa uKhomishane\n",
            "H-2623\t-3.5333175659179688\t.\n",
            "P-2623\t-3.6354 -3.4313\n",
            "S-244\tdled conductor during the\n",
            "T-244\tdled <<unk>> tor isikhathi esiy-\n",
            "H-244\t-3.533318042755127\t.\n",
            "P-244\t-3.6354 -3.4313\n",
            "S-862\tToll-free:\n",
            "T-862\tInombolo yamahhala\n",
            "H-862\t-3.533317804336548\t.\n",
            "P-862\t-3.6354 -3.4313\n",
            "S-154\tA compulsory site\n",
            "T-154\tUmhlangano wokuhlola inda-\n",
            "H-154\t-3.5333175659179688\t.\n",
            "P-154\t-3.6354 -3.4313\n",
            "S-60\tsite visit will be held\n",
            "T-60\tUmhlangano wokuhlola inda-\n",
            "H-60\t-3.5333168506622314\t.\n",
            "P-60\t-3.6354 -3.4313\n",
            "S-817\tProcurement and payments\n",
            "T-817\tUkuthenga nezinkokhelo ;\n",
            "H-817\t-3.533317804336548\t.\n",
            "P-817\t-3.6354 -3.4313\n",
            "S-1958\tRegistration of business names\n",
            "T-1958\tUkubhaliswa kwamagama ebhizinisi\n",
            "H-1958\t-3.533318042755127\t.\n",
            "P-1958\t-3.6354 -3.4313\n",
            "S-2183\tStandard of proof\n",
            "T-2183\tIndinganiso yesiqinisekiso\n",
            "H-2183\t-3.533318042755127\t.\n",
            "P-2183\t-3.6354 -3.4313\n",
            "S-1630\tHistorical context\n",
            "T-1630\tIngqikithi yezomLando\n",
            "H-1630\t-3.533317804336548\t.\n",
            "P-1630\t-3.6354 -3.4313\n",
            "S-1294\tNOTE :\n",
            "T-1294\tQAPHELA:\n",
            "H-1294\t-3.5333175659179688\t.\n",
            "P-1294\t-3.6354 -3.4313\n",
            "S-1990\tResearch and public information\n",
            "T-1990\tUcwaningo nokwaziswa komphakathi\n",
            "H-1990\t-3.5333175659179688\t.\n",
            "P-1990\t-3.6354 -3.4313\n",
            "S-1288\tConsumer Name\n",
            "T-1288\tIgama lekhasimende:\n",
            "H-1288\t-3.5333175659179688\t.\n",
            "P-1288\t-3.6354 -3.4313\n",
            "S-1666\tLanguage policy\n",
            "T-1666\tumthethomgomo wolimi\n",
            "H-1666\t-3.5333173274993896\t.\n",
            "P-1666\t-3.6354 -3.4313\n",
            "S-752\teducation development centres\n",
            "T-752\tIzikhungo zokuthuthukisa imfundo\n",
            "H-752\t-3.5333173274993896\t.\n",
            "P-752\t-3.6354 -3.4313\n",
            "S-2041\tNational and provincial co-operation\n",
            "T-2041\tUkubambisana kukazwelonke nezifundazwe\n",
            "H-2041\t-3.5333170890808105\t.\n",
            "P-2041\t-3.6354 -3.4313\n",
            "S-2191\tProof of facts\n",
            "T-2191\tIsiqinisekiso esiphathekayo\n",
            "H-2191\t-3.5333173274993896\t.\n",
            "P-2191\t-3.6354 -3.4313\n",
            "S-1688\tAssociated Companies\n",
            "T-1688\tIzinkampani ezinobudlelwano\n",
            "H-1688\t-3.5333168506622314\t.\n",
            "P-1688\t-3.6354 -3.4313\n",
            "S-1690\tTimeframe\n",
            "T-1690\tnesikhathi okungaqedwa ngaso umsebenzi\n",
            "H-1690\t-3.533318042755127\t.\n",
            "P-1690\t-3.6354 -3.4313\n",
            "S-208\tVENUE\n",
            "T-208\tINDAWO\n",
            "H-208\t-3.5333168506622314\t.\n",
            "P-208\t-3.6354 -3.4313\n",
            "S-1651\tPanSALB\n",
            "T-1651\tPanSALB Ibhodi yeziLimi yaseNingizimu Afrika\n",
            "H-1651\t-3.533317804336548\t.\n",
            "P-1651\t-3.6354 -3.4313\n",
            "S-1399\tto 500 Nil\n",
            "T-1399\tNGENYANGA 500 Lutho\n",
            "H-1399\t-3.5333166122436523\t.\n",
            "P-1399\t-3.6354 -3.4313\n",
            "S-873\tFax number:\n",
            "T-873\tIFeksi 033-8465185\n",
            "H-873\t-3.5333173274993896\t.\n",
            "P-873\t-3.6354 -3.4313\n",
            "S-76\tA compulsory\n",
            "T-76\two okuyimpoqo ukuwethamela umhla ka2007\n",
            "H-76\t-3.533317804336548\t.\n",
            "P-76\t-3.6354 -3.4313\n",
            "S-645\tSupply and delivery of\n",
            "T-645\tE .8758 Ukuthengisela nokudiliva\n",
            "H-645\t-3.5333175659179688\t.\n",
            "P-645\t-3.6354 -3.4313\n",
            "S-787\tLogistical support\n",
            "T-787\tUkwesekelwa ngokwezinhlelo zemisebenzi ;\n",
            "H-787\t-3.533317804336548\t.\n",
            "P-787\t-3.6354 -3.4313\n",
            "S-1291\tPayments Only\n",
            "T-1291\tUKUKHOKHA KODWA\n",
            "H-1291\t-3.5333170890808105\t.\n",
            "P-1291\t-3.6354 -3.4313\n",
            "S-1033\tby impersonators ;\n",
            "T-1033\tngalabo abazishaya sama- ;\n",
            "H-1033\t-3.533317804336548\t.\n",
            "P-1033\t-3.6354 -3.4313\n",
            "S-2567\tRight to privacy\n",
            "T-2567\tIlungelo lokuhlonishwa kobumfihlo\n",
            "H-2567\t-3.5333173274993896\t.\n",
            "P-2567\t-3.6354 -3.4313\n",
            "S-1728\tFLATS\n",
            "T-1728\tAMAFULETHI\n",
            "H-1728\t-3.5333175659179688\t.\n",
            "P-1728\t-3.6354 -3.4313\n",
            "S-1617\tDepartment of Education\n",
            "T-1617\tDoE UmNyango wezeMfundo\n",
            "H-1617\t-3.5333168506622314\t.\n",
            "P-1617\t-3.6354 -3.4313\n",
            "S-768\tIn this regard we ;\n",
            "T-768\tNgale ndlela:\n",
            "H-768\t-3.533318281173706\t.\n",
            "P-768\t-3.6354 -3.4313\n",
            "S-1460\tOfficial language\n",
            "T-1460\tulimi olusemthethweni\n",
            "H-1460\t-3.5333170890808105\t.\n",
            "P-1460\t-3.6354 -3.4313\n",
            "S-1686\tor by email:\n",
            "T-1686\tnoma nge e-\n",
            "H-1686\t-3.5333166122436523\t.\n",
            "P-1686\t-3.6354 -3.4313\n",
            "S-1552\tLexicography\n",
            "T-1552\tukubhala\n",
            "H-1552\t-3.5333168506622314\t.\n",
            "P-1552\t-3.6354 -3.4313\n",
            "S-1967\tBusiness names\n",
            "T-1967\tAmagama ebhizinisi\n",
            "H-1967\t-3.5333173274993896\t.\n",
            "P-1967\t-3.6354 -3.4313\n",
            "S-1598\tLanguage rights\n",
            "T-1598\tamalungelo olimi\n",
            "H-1598\t-3.5333175659179688\t.\n",
            "P-1598\t-3.6354 -3.4313\n",
            "S-778\tFinancial management .\n",
            "T-778\tUkuphathwa kwezimali ;\n",
            "H-778\t-3.5333168506622314\t.\n",
            "P-778\t-3.6354 -3.4313\n",
            "S-482\tAgrarian revolution\n",
            "T-482\tIvukela kwezolimo\n",
            "H-482\t-3.5333170890808105\t.\n",
            "P-482\t-3.6354 -3.4313\n",
            "S-207\tEnquiries:\n",
            "T-207\tImibuzo:\n",
            "H-207\t-3.533317804336548\t.\n",
            "P-207\t-3.6354 -3.4313\n",
            "S-2036\tAppointment of Commissioner\n",
            "T-2036\tUkukhethwa kukaKhomishane\n",
            "H-2036\t-3.5333173274993896\t.\n",
            "P-2036\t-3.6354 -3.4313\n",
            "S-1305\tDATE :\n",
            "T-1305\tUSUKU\n",
            "H-1305\t-3.5333170890808105\t.\n",
            "P-1305\t-3.6354 -3.4313\n",
            "S-2716\tOutcome of investigation\n",
            "T-2716\tUmphumela wophenyo\n",
            "H-2716\t-3.5333175659179688\t.\n",
            "P-2716\t-3.6354 -3.4313\n",
            "S-3\tTO THE\n",
            "T-3\tE\n",
            "H-3\t-3.5333170890808105\t.\n",
            "P-3\t-3.6354 -3.4313\n",
            "S-1698\tContact:\n",
            "T-1698\tThintana no:\n",
            "H-1698\t-3.533317804336548\t.\n",
            "P-1698\t-3.6354 -3.4313\n",
            "S-993\tEmpathy\n",
            "T-993\tUzwela\n",
            "H-993\t-3.5333170890808105\t.\n",
            "P-993\t-3.6354 -3.4313\n",
            "S-1311\tTariff\n",
            "T-1311\tImali ekhokhwayo\n",
            "H-1311\t-3.5333173274993896\t.\n",
            "P-1311\t-3.6354 -3.4313\n",
            "S-2421\tSection of Act\n",
            "T-2421\tIsigaba soMthetho\n",
            "H-2421\t-3.533318281173706\t.\n",
            "P-2421\t-3.6354 -3.4313\n",
            "S-251\tDATE\n",
            "T-251\tUSUKU ,\n",
            "H-251\t-3.5333173274993896\t.\n",
            "P-251\t-3.6354 -3.4313\n",
            "S-1518\tTranslation\n",
            "T-1518\tUkuhumusha\n",
            "H-1518\t-3.5333173274993896\t.\n",
            "P-1518\t-3.6354 -3.4313\n",
            "S-1912\tInterpretation\n",
            "T-1912\tUkuchazwa\n",
            "H-1912\t-3.5333170890808105\t.\n",
            "P-1912\t-3.6354 -3.4313\n",
            "S-983\tHonesty\n",
            "T-983\tUkwethembeka\n",
            "H-983\t-3.533318042755127\t.\n",
            "P-983\t-3.6354 -3.4313\n",
            "S-98\tThe projects are:\n",
            "T-98\tAmaphrojekthi yilawa: Buffer\n",
            "H-98\t-3.5333173274993896\t.\n",
            "P-98\t-3.6354 -3.4313\n",
            "S-1128\tnational CMP .\n",
            "T-1128\tngokuhambisana noweZwelonke .\n",
            "H-1128\t-3.5333170890808105\t.\n",
            "P-1128\t-3.6354 -3.4313\n",
            "S-1574\tPrinciples\n",
            "T-1574\tImigomo\n",
            "H-1574\t-3.5333173274993896\t.\n",
            "P-1574\t-3.6354 -3.4313\n",
            "S-1453\tIntroduction\n",
            "T-1453\tIsingeniso\n",
            "H-1453\t-3.533317804336548\t.\n",
            "P-1453\t-3.6354 -3.4313\n",
            "S-790\tCorporate Services\n",
            "T-790\tUphiko lwezinhlelo zokuphatha nokwelekelela\n",
            "H-790\t-3.533317804336548\t.\n",
            "P-790\t-3.6354 -3.4313\n",
            "S-282\tTIME\n",
            "T-282\tISIKHATHI ,\n",
            "H-282\t-3.5333175659179688\t.\n",
            "P-282\t-3.6354 -3.4313\n",
            "S-737\tRoad , Durban .\n",
            "T-737\tRoad , eThekwini , ngo 10:00 .\n",
            "H-737\t-3.533317804336548\t.\n",
            "P-737\t-3.6354 -3.4313\n",
            "S-302\tEnquiries :\n",
            "T-302\tYonke imibuzo: Eyobuchwephe-\n",
            "H-302\t-3.5333175659179688\t.\n",
            "P-302\t-3.6354 -3.4313\n",
            "S-128\tcash or bank\n",
            "T-128\tukheshe noma isheke eliqinisekiswe yibhange\n",
            "H-128\t-3.5333170890808105\t.\n",
            "P-128\t-3.6354 -3.4313\n",
            "S-755\tIn this regard ;\n",
            "T-755\tNgale ndlela:\n",
            "H-755\t-3.5333173274993896\t.\n",
            "P-755\t-3.6354 -3.4313\n",
            "S-773\tschool libraries\n",
            "T-773\tImitapo yezikole ;\n",
            "H-773\t-3.5333168506622314\t.\n",
            "P-773\t-3.6354 -3.4313\n",
            "S-2382\tProvincial regulatory capacity\n",
            "T-2382\tAmandla okulawula kweSifundazwe\n",
            "H-2382\t-3.5333175659179688\t.\n",
            "P-2382\t-3.6354 -3.4313\n",
            "S-1635\tTerminology\n",
            "T-1635\tItheminoloji\n",
            "H-1635\t-3.5333173274993896\t.\n",
            "P-1635\t-3.6354 -3.4313\n",
            "S-1731\tExcept for\n",
            "T-1731\tNgaphandle kwamaqon-\n",
            "H-1731\t-3.533317804336548\t.\n",
            "P-1731\t-3.6354 -3.4313\n",
            "S-1909\tPart A\n",
            "T-1909\tIngxenye A\n",
            "H-1909\t-3.5333168506622314\t.\n",
            "P-1909\t-3.6354 -3.4313\n",
            "S-1614\tScope\n",
            "T-1614\tUbubanzi\n",
            "H-1614\t-3.5333175659179688\t.\n",
            "P-1614\t-3.6354 -3.4313\n",
            "S-1567\tAims\n",
            "T-1567\tIzinjongo\n",
            "H-1567\t-3.533318042755127\t.\n",
            "P-1567\t-3.6354 -3.4313\n",
            "S-1544\tFunctional\n",
            "T-1544\tubuliminingi\n",
            "H-1544\t-3.533317804336548\t.\n",
            "P-1544\t-3.6354 -3.4313\n",
            "S-1623\tInterpreting\n",
            "T-1623\tukuhumusha\n",
            "H-1623\t-3.5333173274993896\t.\n",
            "P-1623\t-3.6354 -3.4313\n",
            "S-1307\tItem\n",
            "T-1307\tInombolo\n",
            "H-1307\t-3.5333175659179688\t.\n",
            "P-1307\t-3.6354 -3.4313\n",
            "S-982\tCaring\n",
            "T-982\tUkunakekela\n",
            "H-982\t-3.5333173274993896\t.\n",
            "P-982\t-3.6354 -3.4313\n",
            "S-745\tSkills\n",
            "T-745\tSkills\n",
            "H-745\t-3.533317804336548\t.\n",
            "P-745\t-3.6354 -3.4313\n",
            "S-1584\tEquity\n",
            "T-1584\tukulinganisa\n",
            "H-1584\t-3.5333168506622314\t.\n",
            "P-1584\t-3.6354 -3.4313\n",
            "S-1337\tAddress\n",
            "T-1337\tIkheli\n",
            "H-1337\t-3.533317804336548\t.\n",
            "P-1337\t-3.6354 -3.4313\n",
            "S-373\tThe intention\n",
            "T-373\tInhloso\n",
            "H-373\t-3.533317804336548\t.\n",
            "P-373\t-3.6354 -3.4313\n",
            "S-1916\tApplication of Act\n",
            "T-1916\tUkusebenza koMthetho\n",
            "H-1916\t-3.5333175659179688\t.\n",
            "P-1916\t-3.6354 -3.4313\n",
            "S-4\tOF A\n",
            "T-4\tKO\n",
            "H-4\t-3.533317804336548\t.\n",
            "P-4\t-3.6354 -3.4313\n",
            "S-263\tcash or\n",
            "T-263\tukheshe noma amasheke aqinisek-\n",
            "H-263\t-3.5333175659179688\t.\n",
            "P-263\t-3.6354 -3.4313\n",
            "S-2592\tCommission investigations\n",
            "T-2592\tUphenyo lukaKhomishane\n",
            "H-2592\t-3.5333175659179688\t.\n",
            "P-2592\t-3.6354 -3.4313\n",
            "S-1873\tAuctions\n",
            "T-1873\tIlungelo lomthengi lokwamukela ukuthi umphakeli unalo ilungelo lokuthengisa izimpahla\n",
            "H-1873\t-3.5333168506622314\t.\n",
            "P-1873\t-3.6354 -3.4313\n",
            "S-2619\tFinances\n",
            "T-2619\tUkuzuza Ngokulahlekelwa Komunye Ezezimali\n",
            "H-2619\t-3.5333170890808105\t.\n",
            "P-2619\t-3.6354 -3.4313\n",
            "S-731\tAny objec-\n",
            "T-731\tAbaphikisanayo nalokhu okuh-\n",
            "H-731\t-3.5333175659179688\t.\n",
            "P-731\t-3.6354 -3.4313\n",
            "S-81\tor PO\n",
            "T-81\tnoma kuleli kheli leposi: PO\n",
            "H-81\t-3.533317804336548\t.\n",
            "P-81\t-3.6354 -3.4313\n",
            "S-1010\tFairness\n",
            "T-1010\tUbuqiniso\n",
            "H-1010\t-3.533318042755127\t.\n",
            "P-1010\t-3.6354 -3.4313\n",
            "S-1014\tIntegrity\n",
            "T-1014\tUbuqotho\n",
            "H-1014\t-3.533318281173706\t.\n",
            "P-1014\t-3.6354 -3.4313\n",
            "S-762\tIn this regard\n",
            "T-762\tNgale ndlela:\n",
            "H-762\t-3.5333170890808105\t.\n",
            "P-762\t-3.6354 -3.4313\n",
            "S-1557\tEditing\n",
            "T-1557\tukulungisa Amaphutha\n",
            "H-1557\t-3.5333168506622314\t.\n",
            "P-1557\t-3.6354 -3.4313\n",
            "S-1160\tPart 2\n",
            "T-1160\tIsigaba sesibili .\n",
            "H-1160\t-3.533318042755127\t.\n",
            "P-1160\t-3.6354 -3.4313\n",
            "S-1482\tApproach\n",
            "T-1482\tIndlela Yokusetshenziswa\n",
            "H-1482\t-3.5333173274993896\t.\n",
            "P-1482\t-3.6354 -3.4313\n",
            "S-8\tAND\n",
            "T-8\tFUTHI\n",
            "H-8\t-3.5333168506622314\t.\n",
            "P-8\t-3.6354 -3.4313\n",
            "S-1413\tNo .\n",
            "T-1413\tInombolo\n",
            "H-1413\t-3.5333170890808105\t.\n",
            "P-1413\t-3.6354 -3.4313\n",
            "S-713\tsite meeting\n",
            "T-713\tUmhlangano wabafaka amath-\n",
            "H-713\t-3.5333168506622314\t.\n",
            "P-713\t-3.6354 -3.4313\n",
            "S-1300\tSection\n",
            "T-1300\tIsigaba esithintekayo\n",
            "H-1300\t-3.533318042755127\t.\n",
            "P-1300\t-3.6354 -3.4313\n",
            "S-1744\t&\n",
            "T-1744\tNAMA\n",
            "H-1744\t-3.5333173274993896\t.\n",
            "P-1744\t-3.6354 -3.4313\n",
            "S-82\tDurban\n",
            "T-82\tEthekwini\n",
            "H-82\t-3.5333170890808105\t.\n",
            "P-82\t-3.6354 -3.4313\n",
            "  4% 1/24 [00:00<00:14,  1.54it/s, wps=1103]Traceback (most recent call last):\n",
            "  File \"generate.py\", line 178, in <module>\n",
            "    main(args)\n",
            "  File \"generate.py\", line 111, in main\n",
            "    for sample_id, src_tokens, target_tokens, hypos in translations:\n",
            "  File \"/content/fairseq/fairseq/sequence_generator.py\", line 125, in generate_batched_itr\n",
            "    prefix_tokens=s['target'][:, :prefix_size] if prefix_size > 0 else None,\n",
            "  File \"/content/fairseq/fairseq/sequence_generator.py\", line 148, in generate\n",
            "    return self._generate(encoder_input, beam_size, maxlen, prefix_tokens)\n",
            "  File \"/content/fairseq/fairseq/sequence_generator.py\", line 338, in _generate\n",
            "    lprobs, avg_attn_scores = self._decode(tokens[:, :step + 1], encoder_outs, incremental_states)\n",
            "  File \"/content/fairseq/fairseq/sequence_generator.py\", line 544, in _decode\n",
            "    return self._decode_one(tokens, self.models[0], encoder_outs[0], incremental_states, log_probs=True)\n",
            "  File \"/content/fairseq/fairseq/sequence_generator.py\", line 575, in _decode_one\n",
            "    probs = model.get_normalized_probs(decoder_out, log_probs=log_probs)\n",
            "  File \"/content/fairseq/fairseq/models/fairseq_model.py\", line 41, in get_normalized_probs\n",
            "    return self.decoder.get_normalized_probs(net_output, log_probs, sample)\n",
            "  File \"/content/fairseq/fairseq/models/fairseq_decoder.py\", line 46, in get_normalized_probs\n",
            "    return F.log_softmax(logits, dim=-1)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\", line 1295, in log_softmax\n",
            "    ret = input.log_softmax(dim)\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 8.88 MiB (GPU 0; 11.17 GiB total capacity; 432.56 MiB already allocated; 4.44 MiB free; 17.31 MiB cached)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i5pbRUFYdEpW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**RESULT**\n"
      ]
    },
    {
      "metadata": {
        "id": "by-BYSYGc6Gp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Multilingual\n",
        "Using Transformer, training and validating with multilingual data, and then testing with just zulu data.\n",
        "Should run on various values for bpe. Start with 32 000 just because that is what the Johnson paper does."
      ]
    },
    {
      "metadata": {
        "id": "V2b9irEodHnl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('../')\n",
        "!cat fairseq/ukuxhumana/multilingual/all_parallel.train.en fairseq/ukuxhumana/multilingual/all_parallel.train.all > combine.txt\n",
        "!fairseq/subword-nmt/learn_bpe.py -s 32000 <combine.txt> enall.codes\n",
        "\n",
        "!fairseq/subword-nmt/apply_bpe.py -c enall.codes < fairseq/ukuxhumana/multilingual/all_parallel.train.en > train.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c enall.codes < fairseq/ukuxhumana/multilingual/all_parallel.train.all > train.zu\n",
        "!fairseq/subword-nmt/apply_bpe.py -c enall.codes < fairseq/ukuxhumana/multilingual/all_parallel.dev.en > valid.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c enall.codes < fairseq/ukuxhumana/multilingual/all_parallel.dev.all > valid.zu\n",
        "!fairseq/subword-nmt/apply_bpe.py -c enall.codes < fairseq/ukuxhumana/multilingual/enzu_parallel.test.en > test.en\n",
        "!fairseq/subword-nmt/apply_bpe.py -c enall.codes < fairseq/ukuxhumana/multilingual/enzu_parallel.test.zu > test.zu\n",
        "\n",
        "os.chdir('fairseq/')\n",
        "TEXT=\"..\"\n",
        "%run 'preprocess.py' --source-lang en --target-lang zu --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test --destdir data-bin/enzu\n",
        "\n",
        "!mkdir -p checkpoint/fconv\n",
        "!python train.py data-bin/enzu \\\n",
        "    --lr 0.25 --clip-norm 0.1 --dropout 0.2 --max-tokens 4000 \\\n",
        "    --arch transformer --save-dir checkpoint/fconv\n",
        "\n",
        "# for sentencepiece remove ▁\n",
        "output = %run 'generate.py' data-bin/enzu --path checkpoint/fconv/checkpoint_best.pt --beam 5 --batch-size 128 --remove-bpe --source-lang en --target-lang zu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yQPqnAwydH-R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**RESULT**"
      ]
    },
    {
      "metadata": {
        "id": "jpBqLNsbdKBK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Using Morfessor\n"
      ]
    }
  ]
}